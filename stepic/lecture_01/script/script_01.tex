\documentclass[10pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[OT1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\author{Nikolay Anokhin}

\begin{document}

\section{Введение}

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data Mining как KDD}

\paragraph{Источники} \cite{journeys} \cite{kdd89} \cite{critic}

\begin{enumerate}
\item Определение, данное на слайде часто цитируется во многих источниках. Оно было предложено в статье Fayyad et.al в 1996 году, но сам термин KDD появился на 7 лет раньше.
\item KDD - название, предложенное Григорием Пятецким-Шапиро для семинара, который он организовывал в рамках конференции IJCAI-89. Про воркшоп поговорим чуть позже в рамках исторической справки.
\item Хотя это определение часто цитируется в литературе, оно имеет ряд существенных неточностей.
\item Если интерпретировать valid, как ``точный'', то зачастую возникает противоречие с остальными перечисленными качествами.
\item Расмотрим, например, задачу анализа переписи населеня. Одна из очень точных закономерностей, которую можно извлечь - женщины не служат в армии. Немотря на высокую точность, у этой закономерности нет ни новизны, ни практической полезности.
\item Есть также и проблемы с интерпретируемостью закономмерностей. В случае, когда решение принимается автоматической системой, она не нужна. А для человека интепретируемость - слишком субъективное понятие.
\item Учитывая перечисленные недостатки данного определения, делаем вывод, что нам понадобится что-то получше.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data Mining как моделирование}

\paragraph{Источники} \cite{mmds}

\begin{enumerate}
\item Более удобно рассматривать DM как процесс построения модели, хорошо описывающей данные. При этом можно формально определить модель и выбрать критерий, согласно которому можно утверждать, хорошая эта модель или плохая.
\item Выделяют следующие типы моделей
\begin{itemize}
\item Статистические модели - те, в которых явно формулируется распределение вероятности, порождающее данные, возможно с набором неизвестных параметров. Алгоритм вычисления этих параметров называется алгоритмом обучения модели.
\item Подход, основанный на машинном обучении, характеризуется использованием одного из алгоритмов машинного обучения. При этом в основе алгоритма может лежать или не лежать статистическая модель. Наиболее удачно -- когда мы не знаем о данных ничего.
\item Последнее время стал популярен вычислительный подход. Он подразумевает, что модель -- это ответ на некоторый сложный запрос к данным. Такой подход позволяет делать наиболее слабые предположения о природе данных.
\end{itemize}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Пример 1. Красная икра на новогодний стол}

\paragraph{Источники} \cite[ch. 2.3.4]{bishop}

\begin{itemize}
\item Нужно купить красную икру, при этом важно не перепутать настоящую (дорогую) и искуственную (дешевую). Мы посмотрели в Интернете, сколько стоит икра в разных магазинах и идем выбирать в ближайший.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data Mining -- область на пересечении дисциплин}

\paragraph{Источники} \cite{journeys}

\begin{enumerate}
\item 
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data Mining -- область тысячи имен}

\paragraph{Источники} \cite{journeys}

\begin{enumerate}
\item 
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Некоторые важные события в истории Data Mining}

\paragraph{Источники} \cite{journeys}

\begin{enumerate}
\item KDD 89 - 69 участников, 9 статей, SIGKDD - 2300 участников, 151 статья
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Некоторые важные события в истории Data Mining}

\paragraph{CRISP-DM} \cite{crisp}

\begin{enumerate}
\item 1997 SPSS, Teradata, Daimler AG, NCR Corporation and OHRA
\item более 51 процента используют CRISP-DM
\item итеративный процесс
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{10} 

\bibitem{journeys} \href{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.363.1177&rep=rep1&type=pdf}{Journeys to Data Mining: The Journey of Knowledge Discovery}

\bibitem{kdd89} \href{http://www.kdnuggets.com/gpspubs/sigkdd-explorations-kdd-10-years.html}{Knowledge Discovery in Databases: 10 years after}

\bibitem{critic} \href{http://www.pantaneto.co.uk/issue30/Freitas.htm}{Are We Really Discovering ``Interesting'' Knowledge From Data?}

\bibitem{mmds} \href{http://infolab.stanford.edu/~ullman/mmds/book.pdf}{Mining of Massive Datasets}

\bibitem{bishop} \href{http://www.rmki.kfki.hu/~banmi/elte/Bishop\%20-\%20Pattern\%20Recognition\%20and\%20Machine\%20Learning.pdf}{Pattern Recognition and Machine Learning}

\bibitem{sas} \href{http://blogs.sas.com/content/subconsciousmusings/2014/08/22/looking-backwards-looking-forwards-sas-data-mining-and-machine-learning/}{Looking backwards, looking forwards: SAS, data mining, and machine learning}

\bibitem{crisp} \href{http://www.kdnuggets.com/polls/2002/methodology.htm}{What main methodology are you using for data mining? (Jul 2002)}


\end{thebibliography}

\end{document}