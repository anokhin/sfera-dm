Техносфера. Data Mining 
========

Слайды и материалы курса Data Mining для проекта Техносфера (семестр 2)

## Программа курса

### Модуль 1. Введение в Data Mining

#### Занятие 1. Задачи Data Mining (Николай Анохин)

**Теоретическа часть.** Обзор задач Data Mining. Стандартизация подхода к решению задач Data Mining. Процесс CRISP-DM. Виды данных. Кластеризация, классификация, регрессия. Понятие модели и алгоритма обучения.

**Практическая часть.** Библиотека numpy. Exploratory data analysis.

#### Занятие 2. Задача кластеризации и EM-алгоритм (Николай Анохин)

**Теоретическая часть.** Постановка задачи кластеризации. Функции расстояния. Критерии качества кластеризации. EM-алгоритм. K-means и модификации.

**Практическая часть.** Исследование свойства локальности алгоритма k-means. 

#### Занятие 3. Различные алгоритмы кластеризации (Николай Анохин)

**Теоретическая часть.** Иерархическая кластеризация. Agglomerative и Divisive алгоритмы. Различные виды расстояний между кластерами. Stepwise-optimal алгоритм. Случай неэвклидовых пространств. Критерии выбора количества кластеров: rand, silhouette. DBSCAN.

**Практическая часть.** Исследование влияния функции расстояния между кластерами на результат кластеризации.

#### Занятие 4. Задача классификации (Николай Анохин)

**Теоретическая часть.** Постановка задач классификации и регрессии. Теория принятия решений. Виды моделей. Примеры функций потерь. Переобучение. Метрики качества классификации. MDL. Решающие деревья. Алгоритм CART. 

**Практическая часть.** Использование дерева решений для предсказания категории дохода пользователя.

#### Занятие 5. Naive Bayes (Николай Анохин) 

**Теоретическая часть.** Условная вероятность и теорема Байеса. Нормальное распределение. Naive Bayes: multinomial, binomial, gaussian. Сглаживание. Генеративная модель NB и байесовский вывод. Графические модели.

**Практическая часть.** Использование NB для определения языка текста.

#### Занятие 6. Линейные модели (Николай Анохин)

**Теоретическая часть.** Обобщенные линейные модели. Постановка задачи оптимизации. Примеры критериев. Градиентный спуск. Регуляризация. Метод Maximum Likelihood. Логистическая регрессия.

**Практическая часть.**

#### Занятие 7. Метод опорных векторов (Николай Анохин)

**Теоретическая часть.** Разделяющая поверхность с максимальным зазором. Формулировка задачи оптимизации для случаев линейно-разделимых и линейно-неразделимых классов. Сопряженная задача. Опорные векторы. KKT-условия. SVM для задач классификации и регрессии. Kernel trick. Теорема Мерсера. Примеры функций ядра.

**Практическая часть.** Выбор подходящей функции ядра для различных наборов данных. Grid search.
### Модуль 2. Дополнительные главы Data Mining

#### Занятие 1. (Владимир Гулин)

#### Занятие 2. (Павел Нестеров)

#### Занятие 3. (Павел Нестеров)

#### Занятие 4. (Павел Нестеров)

#### Занятие 5. (Владимир Гулин)

#### Занятие 6. (Владимир Гулин)

### Литература

[bishop] Pattern Recognition and Machine Learning // Cristopher M. Bishop (http://research.microsoft.com/en-us/um/people/cmbishop/prml/)

[duda] Pattern Classification // Richard O. Duda, Peter E. Hart, David G. Stork (http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0471056693.html)

[rajaraman] Mining of Massive Datasets // Anand Rajaraman, Jeffrey Ullman (http://infolab.stanford.edu/~ullman/mmds/book.pdf)
