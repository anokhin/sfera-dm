\documentclass[aspectratio=169]{beamer}

\usetheme{default}

\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[OT1]{fontenc}
\usepackage{amsmath}
\usepackage{url}
\usepackage{hyperref}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{etoolbox}
%\usepackage{caption}
\usepackage{subcaption}
\captionsetup{compatibility=false}
\usepackage{pifont}
%\usepackage{subfigure}
\usepackage{xcolor}
\usepackage{framed}
\definecolor{shadecolor}{cmyk}{0,0,0,1}
\usepackage{empheq}
\usepackage[many]{tcolorbox}
\usepackage{multirow}
\usepackage{tikz}

\makeatletter

\setbeamercolor{title}{fg=white}
\setbeamercolor{frametitle}{fg=black}
\setbeamerfont*{title}{family=\sffamily,size=\LARGE}

\setbeamerfont{page number in head/foot}{size=\scriptsize}
\setbeamertemplate{footline}[frame number]
\let\otp\titlepage
\renewcommand{\titlepage}{\otp\addtocounter{framenumber}{-1}}

\setbeamertemplate{background canvas}{%
	\ifnumequal{\c@framenumber}{0}{%
		\vbox to \paperheight{\vfil\hbox to \paperwidth{\hfil\includegraphics[height=\paperheight]{images/cover.png}\hfil}\vfil}
   }{%
      \ifnumequal{\c@framenumber}{\inserttotalframenumber}{
        \vbox to \paperheight{\vfil\hbox to \paperwidth{\hfil\includegraphics[height=\paperheight]{images/back.png}\hfil}\vfil}
      }{%
         % Other frames
      }%
   }%
}

\makeatother

\beamertemplatenavigationsymbolsempty

\tcbset{highlight math style={enhanced,colframe=red,colback=white,arc=4pt,boxrule=1pt}}

\author{Стройкова Ксения}
\title{\newline \newline \newline Лекция 1 \\ Задачи Data Mining}

\begin{document}

\begin{frame}[plain]
\titlepage
\end{frame}

\begin{frame}{Стройкова Ксения}
\begin{itemize}
	\item 2010 - 2014: .Net разработчик, Skyforge
	\item 2014: Технопарк
	\item 2014: Магистр техники и технологий, информатика и вычислительная техника, МГТУ
	\item 2014 - н.вр.: Программист-исследователь в отделе анализа данных
\end{itemize}

\begin{footnotesize}
e-mail: \href{mailto:k.stroykova@corp.mail.ru}{k.stroykova@corp.mail.ru} \\
тел.: +7 (926) 594-08-14 \\
slack: \url{http://spheremailru.slack.com}
\end{footnotesize}

\end{frame}

\begin{frame}{План лекции}
\tableofcontents
\end{frame}

% =======================
\section{Структура курса}
% =======================

\begin{frame}{Структура курса}

{\small
\begin{enumerate}
\item \underline{Задачи Data Mining}{\color{red}$^{HW1}$}
\item Алгоритмы кластеризации{\color{red}$^{HW2}$}
\item Задача кластеризации и EM-алгоритм{\color{red}$^{HW3}$}
\item Байесовская кластеризация
\item \textbf{Кластеризация: итоговые занятия}{\color{red}$^{K1}$}
\item Задача классификации
\item Naive Bayes и работа с текстом{\color{red}$^{HW4}$}
\item Решающие деревья
\item Линейные модели{\color{red}$^{HW5}$}
\item Метод опорных векторов
\item \textbf{Классификация: итоговое занятие}{\color{red}$^{K2}$}
\item Data Mining в реальных системах
\item \textbf{Защита семестрового проекта}
\end{enumerate}
}

\end{frame}

\begin{frame}{Контроль знаний}

\begin{block}{ДЗ}
\begin{itemize}
\item ДЗ-1, ДЗ-2, ДЗ-4 : максимум 10 баллов за каждое
\item ДЗ-3, ДЗ-5: максимум 15 баллов за каждое
\end{itemize}
\end{block}

\begin{center}
\includegraphics[scale=0.2]{images/hw.png}
\end{center}

\begin{alertblock}{Теория}
\begin{itemize}
\item К-1, К-2 : максимум 10 баллов за каждый
\item Защита проекта: максимум 20 баллов
\item Мини-тесты: максимум 10 баллов
\end{itemize}
\end{alertblock}

\end{frame}

\begin{frame}{Шкала оценок}

\begin{figure}
  \begin{subfigure}[b]{.45\linewidth}
    \centering
    \includegraphics[height=3cm]{images/2.png}
    \caption{0 --- 49}
  \end{subfigure}\hfill
  \begin{subfigure}[b]{.45\linewidth}
    \centering
    \includegraphics[height=3cm]{images/3.png}
    \caption{50 --- 79}
  \end{subfigure}\\
  \begin{subfigure}[b]{.45\linewidth}
    \centering
    \includegraphics[height=3cm]{images/4.png}
    \caption{80 --- 94}
  \end{subfigure}\hfill
  \begin{subfigure}[b]{.45\linewidth}
    \centering
    \includegraphics[height=3cm]{images/5.png}
    \caption{95 --- 100}
  \end{subfigure}%
\end{figure}

\end{frame}

\begin{frame}{Правила}

\begin{itemize}
\item[+] Можно задавать вопросы по ходу лекции
\item[+] Можно входить и выходить, не мешая коллегам
\item[---] Нельзя нарушать порядок в аудитории
\item[---] Нельзя разговаривать по телефону
\item Общение с преподавателем на ``Вы''
\end{itemize}

Ваши правила?

\end{frame}

% =======================
\section{Что такое Data Mining}
% =======================

\begin{frame}{}

\begin{center}
{\LARGE Что такое Data Mining?}

\vspace{2em}
\includegraphics[scale=0.6]{images/joke1.jpg}
\end{center}

\end{frame}


\begin{frame}{Data Mining как KDD}

\begin{quote}{Knowledge Discovery in Databases (KDD)}
-- это процесс получения точных, неизвестных, потенциально полезных и интерпретируемых закономерностей из данных.\footnote{U. Fayyad, G. Piatetsky-Shapiro, P. Smyth. From data mining to knowledge discovery: an overview. 1996}
\end{quote}

\end{frame}

\begin{frame}{Data Mining в KDD}

Этапы KDD
\begin{itemize}
\item selection
\item preprocessing
\item transformation
\item data mining
\item interpretation, evaluation
\end{itemize}

\end{frame}

\begin{frame}{Data Mining как моделирование}

\begin{quote}{Data Mining}
-- процесс построения модели, хорошо описывающей закономерности, которые порождают данные.
\end{quote}

Подходы к построению моделей
\begin{itemize}
\item cтатистический
\item машинное обучение
\item вычислительный
\end{itemize}

\end{frame}

\begin{frame}
\frametitle<1>{Качество вина\footnote{\href{https://archive.ics.uci.edu/ml/datasets/Wine+Quality}{Wine Quality Data Set. UCI Machine Learning Repository}}}
\frametitle<2>{Качество вина: статистический подход}
\frametitle<3>{Качество вина: машинное обучение}
\frametitle<4>{Качество вина: вычислительный подход}

\begin{columns}[c]
    \begin{column}{.49\linewidth}
    \begin{footnotesize}
    \begin{overprint}
				\onslide<1>
				\begin{center}
			\begin{tabular}{r  c  c}
			& ABV, \% & Quality \\
			\hline
			1 & 12.8 & good \\
			2 & 12.8 & good \\
			3 & 10.5 & good \\
			4 & 10.7 & good \\
			5 & 10.7 & good \\
			$\ldots$ & $\ldots$ & $\ldots$ \\
			198 & 11.4 & good \\
			199 & 10.10 & bad \\
			200 & 10.30 & bad \\
			201 & 10.90 & bad \\
			202 & 9.95 & bad \\
			$\ldots$ & $\ldots$ & $\ldots$ \\
			444 & 9.05 & bad \\
			\end{tabular}
			\end{center}
			  \onslide<2>
			  \[
			\begin{cases}
			p( \text{alcohol} \mid \text{good} ) \sim \mathcal{N}(\text{alcohol} \mid \mu_g, \sigma_g) \\
			p( \text{alcohol} \mid \text{bad} ) \sim \mathcal{N}(\text{alcohol} \mid \mu_b, \sigma_b) \\
			\end{cases}
			\]
			\[
			\qquad\qquad\Downarrow (\text{ML-принцип})
			\]
			\[
			\begin{cases}
			\mu_g=11.4, \sigma_g=1.3 \\
			\mu_b=10.2, \sigma_b=1.0
			\end{cases}
			\]
			  \onslide<3>
			  Обучаем линейный SVM:
			  \[\text{alcohol} > 11.2 \Rightarrow \text{good}\]
			  \onslide<4>
			  Подсчитываем параметры данных: \[\langle \text{alcohol} \rangle_g = 11.4,\; \langle \text{alcohol} \rangle_b = 10.2\]
		\end{overprint}
		\end{footnotesize}
    \end{column}
    \begin{column}{.49\linewidth}
    \begin{center}
\includegraphics[width=0.95\textwidth]{images/wine.png}
\end{center}
    \end{column}
\end{columns}

\end{frame}

\begin{frame}{Data Mining -- область на пересечении дисциплин\footnote{\href{http://blogs.sas.com/content/subconsciousmusings/2014/08/22/looking-backwards-looking-forwards-sas-data-mining-and-machine-learning/}{Looking backwards, looking forwards: SAS, data mining, and machine learning}}}

\begin{center}
\includegraphics[width=0.75\textwidth]{images/data-mining-venn.png}
\end{center}

\end{frame}

\begin{frame}{Data Mining -- область тысячи имен}

\begin{enumerate}
\item[1960-е] Data Fishing, Data Dredging
\item[1980-е] Knowledge Discovery in Databases
\item[1990-е] Data Mining, Database mining\textsuperscript{TM}
\item[2000-е] Data Analytics, Data Science\footnote{\href{https://twitter.com/nivertech/status/180109930139893761}{Data Scientist is a Data Analyst who lives in California}}\footnote{\href{https://twitter.com/josh_wills/status/198093512149958656}{A data scientist is someone who is better at statistics than any software engineer and better at software engineering than any statistician.}}
\end{enumerate}

\end{frame}

\begin{frame}{Некоторые важные события в истории Data Mining}

\begin{enumerate}
\item[1989] IJCAI-89 Workshop on Knowledge Discovery in Databases\footnote{\url{http://www.kdnuggets.com/meetings/kdd89/}}
\item[1995] ACM SIGKDD Conference on Knowledge Discovery and Data Mining\footnote{\url{http://www.kdd.org/conferences}}
\item[2001] Leo Breiman's ``Statistical Modeling: The Two Cultures''
\item[2003] Программа Total Information Awareness
\item[2005] Doug Cutting и Mike Cafarella разработали пакет обработки данных Hadoop
\item[2007] Первый релиз библиотки scikit-learn
\item[2010] Заработал сайт Kaggle -- платформа для проведения соревнований по Data Science
\item[2012] Harvard Business Review публикует статью Data Scientist: The Sexiest Job of the 21st Century
\item[2013] Первая встреча сообщества Moscow Data Science\footnote{\url{http://www.meetup.com/Moscow-Data-Science/}} в московском офисе Mail.Ru Group
\end{enumerate}

\end{frame}

\begin{frame}{DM и DS}

\begin{block}{Data Scientist}
Person who is better at statistics than any software engineer and better at software engineering than any statistician \\ (J. Wills, Data Scientist at Cloudera Inc.)
\end{block}

\vspace{1em}
Data-
\begin{itemize}
\item[\color{red}\ding{54}] -architecture
\item[\color{red}\ding{54}] -acquisition
\item[\color{green}\ding{52}] -analysis
\item[\color{red}\ding{54}] -archiving
\end{itemize}

\end{frame}

%\begin{frame}{Success stories}
%
%\begin{figure}
%        \centering
%        \begin{subfigure}[b]{0.45\textwidth}
%                \includegraphics[width=\textwidth]{images/google.png}
%                \caption{Google}
%        \end{subfigure}%
%        \begin{subfigure}[b]{0.45\textwidth}
%                \includegraphics[width=\textwidth]{images/linkedin.png}
%                \caption{LinkedIn}
%        \end{subfigure}
%
%        \begin{subfigure}[b]{0.45\textwidth}
%                \includegraphics[width=\textwidth]{images/delay.png}
%                \caption{KnowDelay}
%        \end{subfigure}%
%        \begin{subfigure}[b]{0.45\textwidth}
%                \includegraphics[width=0.9\textwidth]{images/digits.png}
%                \caption{Handwritten digits}
%        \end{subfigure}
%\end{figure}
%
%\end{frame}

\begin{frame}{Multimedia Data Mining}

\begin{center}
\includegraphics[scale=0.325]{images/multimedia.png}
\end{center}

\end{frame}

\begin{frame}{Data Mining в медицине и биологии}

\begin{center}
\includegraphics[scale=1.5]{images/dna.png}
\end{center}

\end{frame}

\begin{frame}{Data Mining в финансовой сфере}

\begin{itemize}
\item Предсказание биржевых цен
\item Предсказание курса валют
\item Работа с рисками и банкротством
\item Кредитный скоринг
\item Выявление мошенников
\end{itemize}

\end{frame}

\begin{frame}{Data Mining для CRM и целевого маркетинга}

CRM = Customer Relationship Management
\begin{itemize}
\item Как определить, кто собирается уйти?
\item Какие продукты предложить клиенту?
\item Как найти новых клиентов?
\item Реклама!
\end{itemize}

\end{frame}

\begin{frame}{Data Mining для Высшего блага (на самом деле fail)}

\begin{itemize}
\item Наблюдаем $10^9$ человек
\item Человек в среднем посещает отель раз в $100$ дней
\item Есть $10^5$ отелей на $100$ человек каждый
\item Проверим посещения за $1000$ дней
\end{itemize}

Вероятность для конкретной пары встретиться в отеле в конкретный день:
\[
p_1 = \left(\frac{1}{100}\right)^2 \cdot 10^{-5} = 10^{-9}
\]
Всего пар людей
\[
n_{pp} = C^{10^9}_2 \approx \frac{(10^9)^2}{2} = 5 \cdot 10^{17}
\]
а пар дней
\[
n_{pd} = C^{10^3}_2 \approx \frac{(10^3)^2}{2} = 5 \cdot 10^{5}
\]
Ожидаемое количество ``подозрительных'' встреч в отелях
\[
N = p_1^2 n_{pp} n_{pd} = 250000 >> 10
\]

\end{frame}

\begin{frame}{Принцип Бонферрони}

Вычислить количество рассматриваемых событий при предположении их полной случайности. Если это количество намного превосходит количество событий, о котором идет речь в задаче, полученные результаты нельзя будет считать достоверными.

\end{frame}

% =======================
\section{Унификация процесса Data Mining}
% =======================

\begin{frame}{}

\begin{center}
{\LARGE Унификация процесса Data Mining}

\vspace{2em}
\includegraphics[scale=0.6]{images/standards.png}
\end{center}

\end{frame}

\begin{frame}{CRISP-DM}

Cross Industry Standard Process for Data Mining

\begin{center}
\includegraphics[height=0.7\textheight]{images/crisp.png}
\end{center}

\end{frame}

\begin{frame}{Игра в гольф\footnote{Induction of Decision Trees / R. Quinlan}}

\begin{columns}
    \begin{column}{.7\linewidth}
    \begin{small}
    	{\bf Business understanding}
		\begin{itemize}
		\item понимание задачи с точки зрения бизнеса
		\item сбор требований и ограничений
		\item постановка задачи в терминах Data Mining
		\end{itemize}

		$\mathcal{D}$ -- множество, содержащее все рассматриваемые в задаче объекты \\  \vspace{1em}
		$f: \mathcal{D} \rightarrow \mathcal{Y}$ -- целевая функция \\ \vspace{1em}

		Цель -- с использованием данных о конечном множестве объектов из $\mathcal{D}$ (data set) научиться предсказывать значения целевой функции для любых объектов из $\mathcal{D}$

		\vspace{1em}
		Задача {\bf с учителем} -- для ``известных'' объектов дано значение целевой функции, иначе -- задача {\bf без учителя}.
				\end{small}

    \end{column}
    %
    \begin{column}{.3\linewidth}
    \vspace{-0em}
		\begin{center}
   		\includegraphics[width=\textwidth]{images/crisp.png}
    \end{center}
    \end{column}
  \end{columns}

\end{frame}

\begin{frame}{Игра в гольф}

\begin{columns}
    \begin{column}{.7\textwidth}
		{\bf Data understanding}
		\begin{itemize}
		\item первичный сбор данных
		\item ознакомление с данными и понимание их специфики
		\end{itemize}

		\vspace{1em}

		{\bf Data preparation}
		\begin{itemize}
		\item формирование финального набора данных
		\end{itemize}
    \end{column}
    %
    \begin{column}{.3\textwidth}
    \vspace{-0em}
		\begin{center}
   		\includegraphics[width=\textwidth]{images/crisp.png}
    \end{center}
    \end{column}
  \end{columns}

\end{frame}

\begin{frame}{Признаки}

$\mathcal{D}$ -- множество, содержащее все рассматриваемые в задаче объекты \\
$d \in \mathcal{D}$ --  объект,  $\phi_j: \mathcal{D} \rightarrow F_j$ -- признак

\vspace{1em}
Виды признаков
\begin{itemize}
\item Бинарные/Binary \\ $F_j = \{true, false\}$
\item Номинальные/Categorical \\ $F_j$ -- конечное
\item Порядковые/Ordinal \\ $F_j$ -- конечное, упорядоченное
\item Количественные/Numerical \\ $F_j = \mathbb{R}$
\end{itemize}
\vspace{1em}
Признаковое представление объекта $d$
\[
\mathbf{x} = (\phi_1(d), \ldots, \phi_m(d)) \in \mathcal{X}
\]


\end{frame}

\begin{frame}{Игра в гольф: признаки}

\begin{center}
\begin{tabular}{c | c | c | c | c }
\bf Outlook & \bf Temperature & \bf Humidity & \bf Wind & \bf Play \\
\hline
Sunny & 85 & 85 & false & no \\
Sunny & 80 & 90 & true & no \\
Overcast & 83 & 86 & false & yes \\
Rainy & 70 & 96 & false & yes \\
Rainy & 68 & 80 & false & yes \\
Rainy & 65 & 70 & true & no \\
Overcast & 64 & 65 & true & yes \\
Sunny & 72 & 95 & false & no \\
Sunny & 69 & 70 & false & yes \\
Rainy & 75 & 80 & false & yes \\
Sunny & 75 & 70 & true & yes \\
Overcast & 72 & 90 & true & yes \\
Overcast & 81 & 75 & false & yes \\
Rainy & 71 & 91 & true & no \\
\end{tabular}
\end{center}

\end{frame}

\begin{frame}{Моделирование}

\begin{columns}
\begin{column}{.7\textwidth}
    \begin{itemize}
\item перебор различных моделей
\item настройка параметров моделей
\end{itemize}

\begin{block}{Модель}
признаковое описание объекта $d$:
\[
\mathbf{x} = (\phi_1(d), \ldots, \phi_m(d)) \in \mathcal{X}
\]
значение целевой функции для объекта $d$: $f(d) = y \in \mathcal{Y}$

\vspace{1em}
{\bf модель} -- семейство функций вида
\begin{empheq}[box=\tcbhighmath]{align}
H = \{h(\mathbf{x}, \theta) \,:\, \mathcal{X} \times \Theta \rightarrow \mathcal{Y} \},\nonumber
\end{empheq}
где $\theta \in \Theta$ -- неизвестный вектор параметров

\end{block}
    \end{column}
    %
    \begin{column}{.3\textwidth}
    \vspace{-0em}
		\begin{center}
   		\includegraphics[width=\textwidth]{images/crisp.png}
    \end{center}
    \end{column}
  \end{columns}

\end{frame}

\begin{frame}{Виды моделей}

{\bf Генеративные модели.} Смоделировать $p(\mathbf{x} | y_k)$ и $p(y_k)$, применить теорему Байеса
\[
p(y_k | \mathbf{x}) = \frac{p(\mathbf{x} | y_k) p(y_k)}{p(\mathbf{x})}
\]
и использовать $p(y_k | \mathbf{x})$ для принятия решения \\ (NB, Bayes Networks, MRF)
\vspace{1em}

{\bf Дискриминативные модели.} Смоделировать $p(y_k | \mathbf{x})$ и использовать ее для принятия решения \\ (Logistic Regression, Decision Trees)
\vspace{1em}

{\bf Функции решения.} Смоделировать напрямую $h^*(\mathbf{x}): \mathcal{X} \rightarrow \mathcal{Y}$ \\ (SVM, Neural Networks)

\end{frame}

\begin{frame}{Вероятностные модели VS Функции решения}

\begin{itemize}
\item[\color{green}\ding{108}] Отказ от классификации (reject option)
\item[\color{green}\ding{108}] Дисбаланс в выборке
\item[\color{green}\ding{108}] Ансамбли моделей
\item[\color{red}\ding{108}] Сильные предположения о природе данных
\item[\color{red}\ding{108}] Излишняя (вычислительная) сложность
\end{itemize}

\end{frame}

\begin{frame}{Качество вина}

{\bf признаковое описание}: $\mathbf{x} \in \mathbb{R}^1$ \\
\vspace{1em}
{\bf целевая переменная}: $y = 1$, если вино хорошее, $y = 0$ иначе \\
\vspace{1em}
{\bf модель}:
\[
\begin{cases}
p(\mathbf{x} | \text{good}) \sim \mathcal{N}(\mathbf{x} | \mu_g, \sigma_g), \;\; p(\text{good}) = \frac 1 2 \\
p(\mathbf{x} |  \text{bad}) \sim \mathcal{N}(\mathbf{x} | \mu_b, \sigma_b), \;\; p( \text{bad}) = \frac 1 2
\end{cases} \;\; + \quad y = \mathcal{I}(p(\text{good} | \mathbf{x}) > p(\text{bad} | \mathbf{x}))
\]
\vspace{1em}
{\bf параметры}: $\theta = (\mu_g, \sigma_g, \mu_b, \sigma_b)$

\end{frame}

\begin{frame}{Дерево решений}

\begin{columns}
\begin{column}{.5\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{images/dtree.png}
\end{center}
\end{column}
%
\begin{column}{.5\textwidth}
\begin{tiny}
\begin{center}
\begin{tabular}{c | c | c | c | c }
\bf Outlook & \bf Temperature & \bf Humidity & \bf Wind & \bf Play \\
\hline
Sunny & 85 & 85 & false & no \\
Sunny & 80 & 90 & true & no \\
Overcast & 83 & 86 & false & yes \\
Rainy & 70 & 96 & false & yes \\
Rainy & 68 & 80 & false & yes \\
Rainy & 65 & 70 & true & no \\
Overcast & 64 & 65 & true & yes \\
Sunny & 72 & 95 & false & no \\
Sunny & 69 & 70 & false & yes \\
Rainy & 75 & 80 & false & yes \\
Sunny & 75 & 70 & true & yes \\
Overcast & 72 & 90 & true & yes \\
Overcast & 81 & 75 & false & yes \\
Rainy & 71 & 91 & true & no \\
\end{tabular}
\end{center}
\end{tiny}
\end{column}
\end{columns}

\end{frame}

\begin{frame}{Обучение модели}

\begin{itemize}
\item дана обучающая выборка (data set) $X = \{{\mathbf{x}_1, \ldots, \mathbf{x_N}}\}$
\item для каждого из объектов обучающей выборки дано значение целевой функции $Y = \{y_1, \ldots, y_N\}$ (если задача с учителем)
\end{itemize}

\begin{block}{Алгоритм обучения}
Выбор наилучших параметров $\theta^*$ с использованием обучающей выборки
\[
A(X, Y): (\mathcal{X} \times \mathcal{Y})^N \rightarrow \Theta
\]
В итоге:
\[
h^*(\mathbf{x}) = h(\mathbf{x}, \theta^*)
\]
\end{block}

\end{frame}

\begin{frame}{}

\begin{center}
{\large
Learning = Representation + Evaluation + Optimization\footnote{\href{https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf}{A Few Useful Things to Know about Machine Learning // Pedro Domingos}}
}
\end{center}

\end{frame}

\begin{frame}{}

\begin{columns}
    \begin{column}{.7\textwidth}
		{\bf Evaluation}
		\begin{itemize}
		\item тщательная проверка качества модели
		\item подробное рассмотрение шагов, предпринятых при построении
		\item поиск бизнес-требований, которые не удовлетворены
		\end{itemize}

		\vspace{1em}

		{\bf Deployment}
		\begin{itemize}
		\item презентация модели клиенту
		\item развертывание и использование модели
		\end{itemize}
    \end{column}
    %
    \begin{column}{.3\textwidth}
    \vspace{-0em}
		\begin{center}
   		\includegraphics[width=\textwidth]{images/crisp.png}
    \end{center}
    \end{column}
  \end{columns}

\end{frame}

\begin{frame}{Другие процессы: SEMMA\footnote{http://timkienthuc.blogspot.ru/2012/04/crm-and-data-mining-day-08.html}, KDD\footnote{http://www.rithme.eu/}}

\begin{columns}
    \begin{column}{.5\textwidth}
    	\includegraphics[width=\textwidth]{images/semma.png}
    \end{column}

    \begin{column}{.5\textwidth}
    \vspace{-0em}
	\begin{center}
   		\includegraphics[width=\textwidth]{images/kdd.png}
    \end{center}
    \end{column}
  \end{columns}

\end{frame}

% =======================
\section{Exploratory data analysis}
% =======================

\begin{frame}{}

\begin{center}
{\LARGE Exploratory data analysis}

\vspace{2em}
\includegraphics[scale=0.4]{images/piechart.png}
\end{center}

\end{frame}

\begin{frame}{Exploratory data analysis}

EDA направлен на предварительное изучение данных
\begin{itemize}
\item формирование гипотез относительно структуры данных
\item выбор необходимых инструментов анализа
\end{itemize}
Особенность метода состоит в визуализации и поиске важных характеристик и тенденций

\end{frame}

\begin{frame}{Примеры}

\begin{figure}
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=\textwidth]{images/plot.png}
                \caption{Plot}
        \end{subfigure}%
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=\textwidth]{images/scatter.png}
                \caption{Scatter}
        \end{subfigure}
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=\textwidth]{images/bar.png}
                \caption{Barplot}
        \end{subfigure}

        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=\textwidth]{images/pie.png}
                \caption{Piechart}
        \end{subfigure}%
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=\textwidth]{images/heatmap.png}
                \caption{Heatmap}
        \end{subfigure}
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=\textwidth]{images/box.png}
                \caption{Boxplot}
        \end{subfigure}
\end{figure}

\end{frame}

\begin{frame}{Полезные советы}

\begin{columns}[T]
    \begin{column}{.5\textwidth}
    	\begin{itemize}
		\item Все познается в сравнении
		\item Причинно-следственные связи
		\item Размерность имеет значение (больше -- лучше)
		\end{itemize}
    \end{column}
    %
    \begin{column}{.5\textwidth}
    \begin{itemize}
		\item Не избегать пояснений
		\item Content is king
		\end{itemize}
    \end{column}
  \end{columns}

  \begin{center}
   		\includegraphics[width=0.6\textwidth]{images/salaries.png}
    \end{center}

\end{frame}

\begin{frame}{Чтение}

\begin{itemize}
\item \href{https://www.aaai.org/ojs/index.php/aimagazine/article/viewFile/1230/1131}{From data mining to knowledge discovery: an overview}
\item \href{https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf}{A Few Useful Things to Know about Machine Learning}
\item \href{http://infolab.stanford.edu/~ullman/mmds/book.pdf}{Mining of Massive Datasets} Chapters 1.1, 1.2, 1.3.6
\item \href{https://ischool.syr.edu/media/documents/2012/3/DataScienceBook1_1.pdf}{An Introduction to Data Science} Chapter 1
\item \href{https://www.amazon.com/Pattern-Classification-Pt-1-Richard-Duda/dp/0471056693}{Pattern Classification} Chapter 1
\item \href{https://eagereyes.org/blog/2014/my-favorite-charts}{My Favorite Charts blog post}
\item \href{http://www.springer.com/us/book/9780387098227}{CRISP-DM User Guide}
\end{itemize}

\end{frame}

\begin{frame}[plain]
\begin{center}
{\Large Вопросы}
\end{center}
\end{frame}

\end{document}
